{
 "cells": [
  {
   "source": [
    "# D-AT-GRU\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import more_itertools as mit\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from semeval2014.semeval_base import *\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "source": [
    "## Hyper ParamÃ¨tres"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile=\"semeval2014/restaurants-trial.xml\"\n",
    "testfile=\"semeval2014/Restaurants_Test_Data_PhaseA.xml\"\n",
    "corpus = Corpus(ET.parse(trainfile).getroot().findall('sentence'))\n",
    "unseen = Corpus(ET.parse(testfile).getroot().findall('sentence'))\n",
    "b1 = BaselineAspectExtractor(corpus)\n",
    "predicted = b1.tag(unseen.corpus)\n",
    "corpus.write_out('test.predicted-aspect.xml', predicted, short=False)"
   ]
  },
  {
   "source": [
    "## Show 10 sentences and categories example in train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\nfood positive\n\nAnd really large portions.\nfood positive\n\nGo inside and you won't want to leave.\nanecdotes/miscellaneous positive\n\nSave yourself the time and trouble and skip this one!\nanecdotes/miscellaneous negative\n\nThe sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\nfood conflict\n\nService was quick.\nservice positive\n\nOh, don't even let me start with how expensive the bills were!\nprice negative\n\nService is top notch.\nservice positive\n\nThe best thing I tasted were the lambc hops.\nfood positive\n\nOverall I would recommend it and go back again.\nanecdotes/miscellaneous positive\n\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in zip(range(10), corpus.corpus):\n",
    "    print(sentence.text)\n",
    "    for categorie in sentence.aspect_categories:\n",
    "        print(categorie.term, categorie.polarity)\n",
    "    print(\"\")"
   ]
  },
  {
   "source": [
    "## Load Pre-trained Embedding Vectors from Glove (little dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "embedding_dim=50\n",
    "with open(\"embeddings/glove.6B.\"+ str(embedding_dim) +\"d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "source": [
    "## Exemple d'embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.45281  -0.50108  -0.53714  -0.015697  0.22191   0.54602  -0.67301\n -0.6891    0.63493  -0.19726   0.33685   0.7735    0.90094   0.38488\n  0.38367   0.2657   -0.08057   0.61089  -1.2894   -0.22313  -0.61578\n  0.21697   0.35614   0.44499   0.60885  -1.1633   -1.1579    0.36118\n  0.10466  -0.78325   1.4352    0.18629  -0.26112   0.83275  -0.23123\n  0.32481   0.14485  -0.44552   0.33497  -0.95946  -0.097479  0.48138\n -0.43352   0.69455   0.91043  -0.28173   0.41637  -1.2609    0.71278\n  0.23782 ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dict['cat'])"
   ]
  },
  {
   "source": [
    "### Prepare glove embeddings for pytorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training vocab length\n",
    "tknzr = TweetTokenizer() # Use tweetTokenizer because of the internet review style\n",
    "vocab = {}\n",
    "vocab[''] = 0 # Padding\n",
    "vocab['oov'] = 1 # out of Vocabulary\n",
    "for sentence in corpus.corpus:\n",
    "    for word in tknzr.tokenize(sentence.text):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "# Prepare embeddings vocab matrix\n",
    "pretrained_embeds = np.zeros((len(vocab), embedding_dim))\n",
    "oov_embed = np.random.normal(scale=0.5, size=(embedding_dim, ))\n",
    "for i, word in enumerate(vocab):\n",
    "    try: \n",
    "        pretrained_embeds[i] = embeddings_dict[word]\n",
    "    except KeyError:\n",
    "        pretrained_embeds[i] = oov_embed"
   ]
  },
  {
   "source": [
    "## Aspects Extractions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training aspects\n",
    "aspects = {}\n",
    "for sentence in corpus.corpus:     \n",
    "    for aspect in sentence.aspect_categories:\n",
    "        if aspect.term not in aspects:\n",
    "            aspects[aspect.term] = len(aspects)"
   ]
  },
  {
   "source": [
    "## Function to transform polarity to number"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_polarity(polarity):\n",
    "    if polarity == 'positive':\n",
    "        return 0\n",
    "    elif polarity == 'negative':\n",
    "        return 1\n",
    "    elif polarity == 'conflict':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "source": [
    "## Transform dataset to tensor dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensordataset(corpus, dictionary, aspects, batch_size):\n",
    "    res = []\n",
    "    for sentence in corpus.corpus:     \n",
    "        for aspect in sentence.aspect_categories:\n",
    "            res.append(([dictionary[word] if word in dictionary else 1 for word in tknzr.tokenize(sentence.text)], aspects[aspect.term], to_polarity(aspect.polarity)))\n",
    "    random.shuffle(res)\n",
    "    res = [res[x:x+batch_size] for x in range(0, len(res), batch_size)]\n",
    "    batched_result = []\n",
    "    for batch in res:\n",
    "        a,b,c = list(map(list, zip(*batch)))\n",
    "        max_len = 0\n",
    "        for elt in a:\n",
    "            if len(elt) > max_len:\n",
    "                max_len = len(elt)\n",
    "        \n",
    "        a = torch.tensor([list(mit.padded(elt, 0, max_len)) for elt in a], dtype=torch.long)\n",
    "        b = torch.tensor(b, dtype=torch.long).flatten()\n",
    "        c = torch.tensor(c, dtype=torch.int).flatten()\n",
    "        batched_result.append((a,b,c))\n",
    "    return batched_result"
   ]
  },
  {
   "source": [
    "## D-AT-GRU Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_AT_GRU(nn.Module):\n",
    "    def __init__(self, pretrained_embeds, aspects_number):\n",
    "        super(D_AT_GRU, self).__init__() \n",
    "        hidden_size=300\n",
    "        num_layers=1\n",
    "        bias=True\n",
    "        batch_first=True\n",
    "        aspect_size=300\n",
    "        vocab_size, embed_dim = pretrained_embeds.shape\n",
    "        \n",
    "        # Load Glove embeddings\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.word_embeddings.load_state_dict({'weight': torch.FloatTensor(pretrained_embeds)})\n",
    "\n",
    "        # Init GRU \n",
    "        self.gru = nn.GRU(input_size= embed_dim, hidden_size= hidden_size,  \n",
    "                          num_layers= num_layers, bias= bias, \n",
    "                          batch_first= batch_first, bidirectional=False)\n",
    "\n",
    "        # Init random aspects embeddings\n",
    "        self.aspect_embeddings = nn.Embedding(aspects_number, aspect_size)\n",
    "        self.aspect_embeddings.load_state_dict({'weight': self.init_random(aspects_number, aspect_size)})\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, sentence, aspect):\n",
    "        word_embedding = self.word_embeddings(sentence)    \n",
    "        hidden_state, _ = self.gru(word_embedding)\n",
    "        aspect_embedding = self.aspect_embeddings(aspect)\n",
    "\n",
    "        # Resize aspect embedding for sentence length in batch\n",
    "        aspect_embedding = aspect_embedding.unsqueeze_(1)\n",
    "        aspect_embedding = aspect_embedding.expand(-1, sentence[0].size()[0], -1) \n",
    "\n",
    "        hidden_aspect = torch.cat((hidden_state, aspect_embedding), dim=2)\n",
    "        return self.softmax(hidden_aspect)\n",
    "    \n",
    "    def init_random(self, x_size, ysize):\n",
    "        empty = torch.empty(x_size, ysize, dtype=torch.float32, requires_grad=True)\n",
    "        return nn.init.normal_(empty, mean=0, std=0.01)"
   ]
  },
  {
   "source": [
    "## Training cycle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, lr, num_epochs):\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    losses_average = []    \n",
    "    for epoch in range(1,num_epochs+1):       \n",
    "        # Remise Ã  zÃ©ro des gradients\n",
    "        optimizer.zero_grad()\n",
    "        batch_idx = 0\n",
    "        epoch_losses = []\n",
    "        for data, aspect, target in dataset:\n",
    "            batch_idx += 1\n",
    "            # Get Samples\n",
    "            data, aspect, target = Variable(data), Variable(aspect), Variable(target)\n",
    "            \n",
    "            # PrÃ©diction\n",
    "            pred = model(data, aspect)\n",
    "            print(pred)\n",
    "\n",
    "            # Calculer la cross_entropy loss\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(pred, target)\n",
    "\n",
    "            # Sauvegarde des losses pour affichage\n",
    "            epoch_losses.append(loss.data.item())\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "                      \n",
    "            # Affichage\n",
    "            print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(epoch,batch_idx * len(data),len(dataset)*len(data),100. * batch_idx / len(dataset), np.average(epoch_losses)), end='')\n",
    "        print()\n",
    "        losses_average.append(np.average(epoch_losses))\n",
    "    print(\"Evolution of average losse for each epoch:\")\n",
    "    plot(losses_average)\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 23, 300])\ntensor([[[0.0430, 0.0431, 0.0363,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0487, 0.0435, 0.0403,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0458, 0.0461, 0.0440,  ..., 0.0435, 0.0435, 0.0435],\n         ...,\n         [0.0423, 0.0474, 0.0328,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0424, 0.0475, 0.0328,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0424, 0.0476, 0.0328,  ..., 0.0435, 0.0435, 0.0435]],\n\n        [[0.0443, 0.0426, 0.0385,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0427, 0.0388, 0.0481,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0457, 0.0417, 0.0477,  ..., 0.0435, 0.0435, 0.0435],\n         ...,\n         [0.0436, 0.0470, 0.0349,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0436, 0.0470, 0.0349,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0436, 0.0471, 0.0349,  ..., 0.0435, 0.0435, 0.0435]],\n\n        [[0.0453, 0.0426, 0.0395,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0453, 0.0448, 0.0373,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0416, 0.0427, 0.0467,  ..., 0.0435, 0.0435, 0.0435],\n         ...,\n         [0.0447, 0.0470, 0.0357,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0447, 0.0471, 0.0358,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0447, 0.0471, 0.0358,  ..., 0.0435, 0.0435, 0.0435]],\n\n        ...,\n\n        [[0.0457, 0.0466, 0.0316,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0440, 0.0458, 0.0385,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0434, 0.0447, 0.0443,  ..., 0.0435, 0.0435, 0.0435],\n         ...,\n         [0.0434, 0.0420, 0.0439,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0432, 0.0382, 0.0415,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0426, 0.0417, 0.0439,  ..., 0.0435, 0.0435, 0.0435]],\n\n        [[0.0436, 0.0463, 0.0327,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0444, 0.0456, 0.0378,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0448, 0.0420, 0.0478,  ..., 0.0435, 0.0435, 0.0435],\n         ...,\n         [0.0421, 0.0470, 0.0413,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0434, 0.0496, 0.0340,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0434, 0.0502, 0.0314,  ..., 0.0435, 0.0435, 0.0435]],\n\n        [[0.0444, 0.0415, 0.0393,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0394, 0.0443, 0.0476,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0421, 0.0457, 0.0497,  ..., 0.0435, 0.0435, 0.0435],\n         ...,\n         [0.0438, 0.0459, 0.0356,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0438, 0.0459, 0.0356,  ..., 0.0435, 0.0435, 0.0435],\n         [0.0438, 0.0459, 0.0356,  ..., 0.0435, 0.0435, 0.0435]]],\n       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected target size (10, 600), got torch.Size([10])",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-5cdfa1664916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_AT_GRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tensordataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-2a4ba59fcbdd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, lr, num_epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Calculer la cross_entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Sauvegarde des losses pour affichage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 2274\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   2275\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (10, 600), got torch.Size([10])"
     ]
    }
   ],
   "source": [
    "train(D_AT_GRU(pretrained_embeds, len(aspects)), to_tensordataset(corpus, vocab, aspects, 10), 0.01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'food': 0,\n",
       " 'anecdotes/miscellaneous': 1,\n",
       " 'service': 2,\n",
       " 'price': 3,\n",
       " 'ambience': 4}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "aspects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}