{
 "cells": [
  {
   "source": [
    "# D-AT-GRU\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import more_itertools as mit\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from semeval2014.semeval_base import *\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "source": [
    "## Hyper ParamÃ¨tres"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile=\"semeval2014/restaurants-trial.xml\"\n",
    "testfile=\"semeval2014/Restaurants_Test_Data_PhaseA.xml\"\n",
    "corpus = Corpus(ET.parse(trainfile).getroot().findall('sentence'))\n",
    "unseen = Corpus(ET.parse(testfile).getroot().findall('sentence'))\n",
    "b1 = BaselineAspectExtractor(corpus)\n",
    "predicted = b1.tag(unseen.corpus)\n",
    "corpus.write_out('test.predicted-aspect.xml', predicted, short=False)"
   ]
  },
  {
   "source": [
    "## Show 10 sentences and categories example in train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\nfood positive\n\nAnd really large portions.\nfood positive\n\nGo inside and you won't want to leave.\nanecdotes/miscellaneous positive\n\nSave yourself the time and trouble and skip this one!\nanecdotes/miscellaneous negative\n\nThe sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\nfood conflict\n\nService was quick.\nservice positive\n\nOh, don't even let me start with how expensive the bills were!\nprice negative\n\nService is top notch.\nservice positive\n\nThe best thing I tasted were the lambc hops.\nfood positive\n\nOverall I would recommend it and go back again.\nanecdotes/miscellaneous positive\n\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in zip(range(10), corpus.corpus):\n",
    "    print(sentence.text)\n",
    "    for categorie in sentence.aspect_categories:\n",
    "        print(categorie.term, categorie.polarity)\n",
    "    print(\"\")"
   ]
  },
  {
   "source": [
    "## Load Pre-trained Embedding Vectors from Glove (little dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "embedding_dim=50\n",
    "with open(\"embeddings/glove.6B.\"+ str(embedding_dim) +\"d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "source": [
    "## Exemple d'embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.45281  -0.50108  -0.53714  -0.015697  0.22191   0.54602  -0.67301\n -0.6891    0.63493  -0.19726   0.33685   0.7735    0.90094   0.38488\n  0.38367   0.2657   -0.08057   0.61089  -1.2894   -0.22313  -0.61578\n  0.21697   0.35614   0.44499   0.60885  -1.1633   -1.1579    0.36118\n  0.10466  -0.78325   1.4352    0.18629  -0.26112   0.83275  -0.23123\n  0.32481   0.14485  -0.44552   0.33497  -0.95946  -0.097479  0.48138\n -0.43352   0.69455   0.91043  -0.28173   0.41637  -1.2609    0.71278\n  0.23782 ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dict['cat'])"
   ]
  },
  {
   "source": [
    "### Prepare glove embeddings for pytorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training vocab length\n",
    "tknzr = TweetTokenizer() # Use tweetTokenizer because of the internet review style\n",
    "vocab = {}\n",
    "vocab[''] = 0 # Padding\n",
    "vocab['oov'] = 1 # out of Vocabulary\n",
    "for sentence in corpus.corpus:\n",
    "    for word in tknzr.tokenize(sentence.text):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "# Prepare embeddings vocab matrix\n",
    "pretrained_embeds = np.zeros((len(vocab), embedding_dim))\n",
    "oov_embed = np.random.normal(scale=0.5, size=(embedding_dim, ))\n",
    "for i, word in enumerate(vocab):\n",
    "    try: \n",
    "        pretrained_embeds[i] = embeddings_dict[word]\n",
    "    except KeyError:\n",
    "        pretrained_embeds[i] = oov_embed"
   ]
  },
  {
   "source": [
    "## Aspects Extractions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training aspects\n",
    "aspects = {}\n",
    "for sentence in corpus.corpus:     \n",
    "    for aspect in sentence.aspect_categories:\n",
    "        if aspect.term not in aspects:\n",
    "            aspects[aspect.term] = len(aspects)"
   ]
  },
  {
   "source": [
    "## Function to transform polarity to number"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_polarity(polarity):\n",
    "    if polarity == 'positive':\n",
    "        return 0\n",
    "    elif polarity == 'negative':\n",
    "        return 1\n",
    "    elif polarity == 'conflict':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "source": [
    "## Transform dataset to tensor dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensordataset(corpus, dictionary, aspects, batch_size):\n",
    "    res = []\n",
    "    for sentence in corpus.corpus:     \n",
    "        for aspect in sentence.aspect_categories:\n",
    "            res.append(([dictionary[word] if word in dictionary else 1 for word in tknzr.tokenize(sentence.text)], aspects[aspect.term], to_polarity(aspect.polarity)))\n",
    "    random.shuffle(res)\n",
    "    res = [res[x:x+batch_size] for x in range(0, len(res), batch_size)]\n",
    "    batched_result = []\n",
    "    for batch in res:\n",
    "        a,b,c = list(map(list, zip(*batch)))\n",
    "        max_len = 0\n",
    "        for elt in a:\n",
    "            if len(elt) > max_len:\n",
    "                max_len = len(elt)\n",
    "        \n",
    "        a = torch.tensor([list(mit.padded(elt, 0, max_len)) for elt in a], dtype=torch.long)\n",
    "        b = torch.tensor(b, dtype=torch.long).flatten()\n",
    "        c = torch.tensor(c, dtype=torch.int).flatten()\n",
    "        batched_result.append((a,b,c))\n",
    "    return batched_result"
   ]
  },
  {
   "source": [
    "## D-AT-GRU Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_AT_GRU(nn.Module):\n",
    "    def __init__(self, pretrained_embeds, aspects_number):\n",
    "        super(D_AT_GRU, self).__init__() \n",
    "        hidden_size=300\n",
    "        num_layers=1\n",
    "        bias=True\n",
    "        batch_first=True\n",
    "        aspect_size=300\n",
    "        vocab_size, embed_dim = pretrained_embeds.shape\n",
    "        \n",
    "        # Load Glove embeddings\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.word_embeddings.from_pretrained(torch.FloatTensor(pretrained_embeds))\n",
    "\n",
    "        # Init GRU \n",
    "        self.gru = nn.GRU(input_size= embed_dim, hidden_size= hidden_size,  \n",
    "                          num_layers= num_layers, bias= bias, \n",
    "                          batch_first= batch_first, bidirectional=False)\n",
    "\n",
    "        # Init random aspects embeddings\n",
    "        self.aspect_embeddings = nn.Embedding.from_pretrained(self.init_random(aspects_number, aspect_size))\n",
    "\n",
    "        # Init positive attention\n",
    "        self.W_p = Parameter(self.init_random(hidden_size, hidden_size + aspect_size))\n",
    "        self.b_p = Parameter(self.init_random(hidden_size, 1)).squeeze()\n",
    "        self.u_p = Parameter(self.init_random(hidden_size, 1))\n",
    "\n",
    "        # Init negative attention\n",
    "        self.W_n = Parameter(self.init_random(hidden_size, hidden_size + aspect_size))\n",
    "        self.b_n = Parameter(self.init_random(hidden_size, 1)).squeeze()\n",
    "        self.u_n = Parameter(self.init_random(hidden_size, 1))\n",
    "\n",
    "        # Init gates\n",
    "        self.W_py = Parameter(self.init_random(1, hidden_size + aspect_size))\n",
    "        self.b_py = Parameter(self.init_random(1, 1).squeeze())\n",
    "        self.W_ny = Parameter(self.init_random(1, hidden_size + aspect_size))\n",
    "        self.b_ny = Parameter(self.init_random(1, 1).squeeze())\n",
    "\n",
    "        # Softmax function\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Identity matrix\n",
    "        self.I = torch.eye(128,128)\n",
    "\n",
    "    def forward(self, sentence, aspect):    \n",
    "        batch_size = sentence.size()[0]\n",
    "        sentence_length = sentence.size()[1]  \n",
    "        \n",
    "        word_embedding = self.word_embeddings(sentence)   \n",
    "        hidden_state, _ = self.gru(word_embedding)\n",
    "        aspect_embedding = self.aspect_embeddings(aspect)\n",
    "\n",
    "        # Resize aspect embedding for sentence length in batch\n",
    "        aspect_embedding = aspect_embedding.unsqueeze_(1)\n",
    "        aspect_embedding = aspect_embedding.expand(-1, sentence_length, -1) \n",
    "\n",
    "        # Concat hidden_state and aspect_embedding for attention calculation\n",
    "        hidden_plus_aspect = torch.cat((hidden_state, aspect_embedding), dim=2)\n",
    "\n",
    "        # Positive attention calculation\n",
    "        positive_attention = torch.tanh(F.linear(hidden_plus_aspect, self.W_p) + self.b_p)\n",
    "        positive_attention = F.linear(positive_attention, self.u_p.t())\n",
    "        # Remove 3-dim and transpose to get (sentence_length, batch_size)\n",
    "        positive_attention = positive_attention.squeeze(2)\n",
    "        # Attention calculation for each word in sentence \n",
    "        positive_attention = self.softmax(positive_attention).unsqueeze(1)\n",
    "\n",
    "        # Negative attention calculation\n",
    "        negative_attention = torch.tanh(F.linear(hidden_plus_aspect, self.W_n) + self.b_n)\n",
    "        negative_attention = F.linear(negative_attention, self.u_n.t())\n",
    "        # Remove 3-dim and transpose to get (sentence_length, batch_size)\n",
    "        negative_attention = negative_attention.squeeze(2)\n",
    "        # Attention calculation for each word in sentence\n",
    "        negative_attention = self.softmax(negative_attention).unsqueeze(1)\n",
    "\n",
    "        # Text representation: Gate mechanism\n",
    "        positive_gate = torch.bmm(positive_attention, hidden_state).squeeze(1)\n",
    "        negative_gate = torch.bmm(negative_attention, hidden_state).squeeze(1)\n",
    "        \n",
    "        # Classification layer\n",
    "        positive_layer = F.linear(torch.cat((positive_gate, self.aspect_embeddings(aspect).squeeze(1)), dim=1), self.W_py, self.b_py)\n",
    "        negative_layer = F.linear(torch.cat((negative_gate, self.aspect_embeddings(aspect).squeeze(1)), dim=1), self.W_ny, self.b_ny)\n",
    "        classification = torch.cat((positive_layer, negative_layer), dim=1)\n",
    "\n",
    "        # Regularization\n",
    "        regularization = torch.cat((positive_attention, negative_attention), dim=1)\n",
    "        regularization = torch.bmm(regularization.permute(0, 2, 1), regularization) \n",
    "        regularization = regularization - self.I[:sentence_length,:sentence_length].expand(regularization.size(0), -1, -1)\n",
    "        loss = torch.norm(regularization) / sentence_length\n",
    "\n",
    "        return classification, loss\n",
    "\n",
    "    def init_random(self, x_size, ysize):\n",
    "        empty = torch.empty(x_size, ysize, dtype=torch.float32, requires_grad=True)\n",
    "        return nn.init.normal_(empty, mean=0, std=0.01)"
   ]
  },
  {
   "source": [
    "## Label transformation (post-processing)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_tranformation(predictions, P=0.5):\n",
    "    result = []\n",
    "    for prediction in predictions:\n",
    "        y_p = prediction[0].item()\n",
    "        y_n = prediction[1].item()\n",
    "        if y_p > P and y_n > P:\n",
    "            result.append(2)\n",
    "        elif y_p <= P and y_n <= P:\n",
    "            result.append(3)\n",
    "        elif y_p <= P and y_n > P:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "source": [
    "## Training cycle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, lr, num_epochs):\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    losses_average = []    \n",
    "    for epoch in range(1,num_epochs+1):       \n",
    "        # Remise Ã  zÃ©ro des gradients\n",
    "        optimizer.zero_grad()\n",
    "        batch_idx = 0\n",
    "        epoch_losses = []\n",
    "        for data, aspect, target in dataset:\n",
    "            batch_idx += 1\n",
    "            # Get Samples\n",
    "            data, aspect, target = Variable(data), Variable(aspect), Variable(target)\n",
    "            \n",
    "            # PrÃ©diction\n",
    "            pred, loss = model(data, aspect)\n",
    "            print(pred)\n",
    "            print(loss)\n",
    "            print(target)\n",
    "            print(label_tranformation(pred))\n",
    "\n",
    "            # Calculer la cross_entropy loss\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(label_tranformation(pred), target)\n",
    "\n",
    "            # Sauvegarde des losses pour affichage\n",
    "            epoch_losses.append(loss.data.item())\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "                      \n",
    "            # Affichage\n",
    "            print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(epoch,batch_idx * len(data),len(dataset)*len(data),100. * batch_idx / len(dataset), np.average(epoch_losses)), end='')\n",
    "        print()\n",
    "        losses_average.append(np.average(epoch_losses))\n",
    "    print(\"Evolution of average losse for each epoch:\")\n",
    "    plot(losses_average)\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.0101,  0.0157],\n        [-0.0160,  0.0186],\n        [-0.0604,  0.0560],\n        [-0.0074,  0.0217],\n        [ 0.0018,  0.0149],\n        [-0.0501,  0.0479],\n        [-0.0345,  0.0312],\n        [-0.0408,  0.0476],\n        [-0.0061,  0.0103],\n        [-0.0254,  0.0175]], grad_fn=<CatBackward>)\ntensor(0.6184, grad_fn=<DivBackward0>)\ntensor([0, 1, 0, 0, 0, 0, 0, 0, 3, 0], dtype=torch.int32)\n[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'log_softmax'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5cdfa1664916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_AT_GRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tensordataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-e201ec4840f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, lr, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Calculer la cross_entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_tranformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Sauvegarde des losses pour affichage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'log_softmax'"
     ]
    }
   ],
   "source": [
    "train(D_AT_GRU(pretrained_embeds, len(aspects)), to_tensordataset(corpus, vocab, aspects, 10), 0.01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}