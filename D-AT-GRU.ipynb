{
 "cells": [
  {
   "source": [
    "# D-AT-GRU\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from semeval2014.semeval_base import *\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "source": [
    "## Hyper Param√®tres"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile=\"semeval2014/restaurants-trial.xml\"\n",
    "testfile=\"semeval2014/Restaurants_Test_Data_PhaseA.xml\"\n",
    "corpus = Corpus(ET.parse(trainfile).getroot().findall('sentence'))\n",
    "unseen = Corpus(ET.parse(testfile).getroot().findall('sentence'))\n",
    "b1 = BaselineAspectExtractor(corpus)\n",
    "predicted = b1.tag(unseen.corpus)\n",
    "corpus.write_out('test.predicted-aspect.xml', predicted, short=False)"
   ]
  },
  {
   "source": [
    "## Show 10 sentences and categories example in train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\nfood positive\n\nAnd really large portions.\nfood positive\n\nGo inside and you won't want to leave.\nanecdotes/miscellaneous positive\n\nSave yourself the time and trouble and skip this one!\nanecdotes/miscellaneous negative\n\nThe sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\nfood conflict\n\nService was quick.\nservice positive\n\nOh, don't even let me start with how expensive the bills were!\nprice negative\n\nService is top notch.\nservice positive\n\nThe best thing I tasted were the lambc hops.\nfood positive\n\nOverall I would recommend it and go back again.\nanecdotes/miscellaneous positive\n\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in zip(range(10), corpus.corpus):\n",
    "    print(sentence.text)\n",
    "    for categorie in sentence.aspect_categories:\n",
    "        print(categorie.term, categorie.polarity)\n",
    "    print(\"\")"
   ]
  },
  {
   "source": [
    "## Load Pre-trained Embedding Vectors from Glove (little dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "embedding_dim=50\n",
    "with open(\"embeddings/glove.6B.\"+ str(embedding_dim) +\"d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "source": [
    "## Exemple d'embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.45281  -0.50108  -0.53714  -0.015697  0.22191   0.54602  -0.67301\n -0.6891    0.63493  -0.19726   0.33685   0.7735    0.90094   0.38488\n  0.38367   0.2657   -0.08057   0.61089  -1.2894   -0.22313  -0.61578\n  0.21697   0.35614   0.44499   0.60885  -1.1633   -1.1579    0.36118\n  0.10466  -0.78325   1.4352    0.18629  -0.26112   0.83275  -0.23123\n  0.32481   0.14485  -0.44552   0.33497  -0.95946  -0.097479  0.48138\n -0.43352   0.69455   0.91043  -0.28173   0.41637  -1.2609    0.71278\n  0.23782 ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dict['cat'])"
   ]
  },
  {
   "source": [
    "### Prepare glove embeddings to pytorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All\nAnd\nGo\nwon't\nSave\nThe\nrasamalai\nService\nOh\ndon't\nI\nlambc\nOverall\nI've\nEven\nIn\nRao's\nWed\nAnyway\nBut\nTom\nKha\nTry\nReasonable\nEverything\nSala\nThai\nwell-portioned\nAdd\nUnfortunately\nNOT\nTheir\nvomit-inducing\nYUCK\nA\ndidn't\nwouldn't\nWhile\nOur\nMy\nGood\nConsistently\nJapanese\nTapas\nRuby\nFoo's\nNow\nit's\ncan't\nDon't\nOne\nNight\nTokyo\nDefinately\nYou\nAs\nTristate\nWith\nIndian\ncouldn't\nWe\ndissappointed\nThis\nwe'll\nOU\nMUST\nTRY\nTHIS\nRESTAURANT\nHave\nGinger\nHouse\nhaven't\nvirgnin\nDrawbacks\nIt\nBrooklyn\nJoya\nGreat\nIf\nthey'd\nWas\nI'm\nWhat\nExcellent\nDefinitely\nItalian\nNew\nYork\nCity\nLove\nYUKA\nwe're\nwe've\nguaranteeed\nisn't\nAfter\nHUGE\nyou'll\nNY\nWent\nWe've\n375\n"
     ]
    }
   ],
   "source": [
    "# Get training vocab length\n",
    "tknzr = TweetTokenizer() # Use tweetTokenizer because of the internet review style\n",
    "vocab = {}\n",
    "for sentence in corpus.corpus:\n",
    "    for word in tknzr.tokenize(sentence.text):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1        \n",
    "        else:\n",
    "            vocab[word] = vocab[word] + 1\n",
    "\n",
    "# Prepare embeddings vocab matrix\n",
    "pretrained_embeds = np.zeros((len(vocab), embedding_dim))\n",
    "for i, word in enumerate(vocab):\n",
    "    try: \n",
    "        pretrained_embeds[i] = embeddings_dict[word]\n",
    "    except KeyError:\n",
    "        pretrained_embeds[i] = np.random.normal(scale=0.5, size=(embedding_dim, ))"
   ]
  },
  {
   "source": [
    "## D-AT-GRU Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_AT_GRU(nn.Module):\n",
    "    def __init__(self, pretrained_embeds):\n",
    "        super(D_AT_GRU, self).__init__() \n",
    "        hidden_size=300\n",
    "        num_layers=1\n",
    "        bias=True\n",
    "        batch_first=True\n",
    "        aspect_size=300\n",
    "        vocab_size, embed_dim = pretrained_embeds.size()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        # Chargement des embeddings glove\n",
    "        self.word_embeddings.load_state_dict({'weight': pretrained_embeds})\n",
    "    \n",
    "        self.gru = nn.GRU(input_size= embed_dim, hidden_size= hidden_size,  \n",
    "                          num_layers= num_layers, bias= bias, \n",
    "                          batch_first= batch_first, bidirectional=False)\n",
    "        self.aspect_embeddings = nn.Embedding(aspect_size, embed_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.word_embeddings(x)\n",
    "        output, _ = self.gru(embeds)     \n",
    "        return self.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}