{
 "cells": [
  {
   "source": [
    "# D-AT-GRU\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import more_itertools as mit\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from semeval2014.semeval_base import *\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "source": [
    "## Hyper ParamÃ¨tres"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile=\"semeval2014/restaurants-trial.xml\"\n",
    "testfile=\"semeval2014/Restaurants_Test_Data_PhaseA.xml\"\n",
    "corpus = Corpus(ET.parse(trainfile).getroot().findall('sentence'))\n",
    "unseen = Corpus(ET.parse(testfile).getroot().findall('sentence'))\n",
    "b1 = BaselineAspectExtractor(corpus)\n",
    "predicted = b1.tag(unseen.corpus)\n",
    "corpus.write_out('test.predicted-aspect.xml', predicted, short=False)"
   ]
  },
  {
   "source": [
    "## Show 10 sentences and categories example in train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\nfood positive\n\nAnd really large portions.\nfood positive\n\nGo inside and you won't want to leave.\nanecdotes/miscellaneous positive\n\nSave yourself the time and trouble and skip this one!\nanecdotes/miscellaneous negative\n\nThe sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\nfood conflict\n\nService was quick.\nservice positive\n\nOh, don't even let me start with how expensive the bills were!\nprice negative\n\nService is top notch.\nservice positive\n\nThe best thing I tasted were the lambc hops.\nfood positive\n\nOverall I would recommend it and go back again.\nanecdotes/miscellaneous positive\n\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in zip(range(10), corpus.corpus):\n",
    "    print(sentence.text)\n",
    "    for categorie in sentence.aspect_categories:\n",
    "        print(categorie.term, categorie.polarity)\n",
    "    print(\"\")"
   ]
  },
  {
   "source": [
    "## Load Pre-trained Embedding Vectors from Glove (little dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "embedding_dim=50\n",
    "with open(\"embeddings/glove.6B.\"+ str(embedding_dim) +\"d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "source": [
    "## Exemple d'embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.45281  -0.50108  -0.53714  -0.015697  0.22191   0.54602  -0.67301\n -0.6891    0.63493  -0.19726   0.33685   0.7735    0.90094   0.38488\n  0.38367   0.2657   -0.08057   0.61089  -1.2894   -0.22313  -0.61578\n  0.21697   0.35614   0.44499   0.60885  -1.1633   -1.1579    0.36118\n  0.10466  -0.78325   1.4352    0.18629  -0.26112   0.83275  -0.23123\n  0.32481   0.14485  -0.44552   0.33497  -0.95946  -0.097479  0.48138\n -0.43352   0.69455   0.91043  -0.28173   0.41637  -1.2609    0.71278\n  0.23782 ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dict['cat'])"
   ]
  },
  {
   "source": [
    "### Prepare glove embeddings for pytorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training vocab length\n",
    "tknzr = TweetTokenizer() # Use tweetTokenizer because of the internet review style\n",
    "vocab = {}\n",
    "vocab[''] = 0 # Padding\n",
    "vocab['oov'] = 1 # out of Vocabulary\n",
    "for sentence in corpus.corpus:\n",
    "    for word in tknzr.tokenize(sentence.text):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "# Prepare embeddings vocab matrix\n",
    "pretrained_embeds = np.zeros((len(vocab), embedding_dim))\n",
    "oov_embed = np.random.normal(scale=0.5, size=(embedding_dim, ))\n",
    "for i, word in enumerate(vocab):\n",
    "    try: \n",
    "        pretrained_embeds[i] = embeddings_dict[word]\n",
    "    except KeyError:\n",
    "        pretrained_embeds[i] = oov_embed"
   ]
  },
  {
   "source": [
    "## Aspects Extractions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training aspects\n",
    "aspects = {}\n",
    "for sentence in corpus.corpus:     \n",
    "    for aspect in sentence.aspect_categories:\n",
    "        if aspect.term not in aspects:\n",
    "            aspects[aspect.term] = len(aspects)"
   ]
  },
  {
   "source": [
    "## Function to transform polarity to number"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_polarity(polarity):\n",
    "    if polarity == 'positive':\n",
    "        return 0\n",
    "    elif polarity == 'negative':\n",
    "        return 1\n",
    "    elif polarity == 'conflict':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "source": [
    "## Transform dataset to tensor dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensordataset(corpus, dictionary, aspects, batch_size):\n",
    "    res = []\n",
    "    for sentence in corpus.corpus:     \n",
    "        for aspect in sentence.aspect_categories:\n",
    "            res.append(([dictionary[word] if word in dictionary else 1 for word in tknzr.tokenize(sentence.text)], aspects[aspect.term], to_polarity(aspect.polarity)))\n",
    "    random.shuffle(res)\n",
    "    res = [res[x:x+batch_size] for x in range(0, len(res), batch_size)]\n",
    "    batched_result = []\n",
    "    for batch in res:\n",
    "        a,b,c = list(map(list, zip(*batch)))\n",
    "        max_len = 0\n",
    "        for elt in a:\n",
    "            if len(elt) > max_len:\n",
    "                max_len = len(elt)\n",
    "        \n",
    "        a = torch.tensor([list(mit.padded(elt, 0, max_len)) for elt in a], dtype=torch.long)\n",
    "        b = torch.tensor(b, dtype=torch.long).flatten()\n",
    "        c = torch.tensor(c, dtype=torch.int).flatten()\n",
    "        batched_result.append((a,b,c))\n",
    "    return batched_result"
   ]
  },
  {
   "source": [
    "## D-AT-GRU Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_AT_GRU(nn.Module):\n",
    "    def __init__(self, pretrained_embeds, aspects_number):\n",
    "        super(D_AT_GRU, self).__init__() \n",
    "        hidden_size=300\n",
    "        num_layers=1\n",
    "        bias=True\n",
    "        batch_first=True\n",
    "        aspect_size=300\n",
    "        vocab_size, embed_dim = pretrained_embeds.shape\n",
    "        \n",
    "        # Load Glove embeddings\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.word_embeddings.load_state_dict({'weight': torch.FloatTensor(pretrained_embeds)})\n",
    "\n",
    "        # Init GRU \n",
    "        self.gru = nn.GRU(input_size= embed_dim, hidden_size= hidden_size,  \n",
    "                          num_layers= num_layers, bias= bias, \n",
    "                          batch_first= batch_first, bidirectional=False)\n",
    "\n",
    "        # Init random aspects embeddings\n",
    "        self.aspect_embeddings = nn.Embedding(aspects_number, aspect_size)\n",
    "        self.aspect_embeddings.load_state_dict({'weight': self.init_random(aspects_number, aspect_size)})\n",
    "\n",
    "        # Init positive attention\n",
    "        self.W_p = Parameter(self.init_random(hidden_size, hidden_size+aspect_size))\n",
    "        self.b_p = Parameter(self.init_random(hidden_size, 1)).squeeze()\n",
    "        self.u_p = Parameter(self.init_random(1, hidden_size))\n",
    "\n",
    "        # Init negative attention\n",
    "        self.W_n = Parameter(self.init_random(hidden_size, hidden_size+aspect_size))\n",
    "        self.b_n = Parameter(self.init_random(hidden_size, 1)).squeeze()\n",
    "        self.u_n = Parameter(self.init_random(1, hidden_size))\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, sentence, aspect):\n",
    "        word_embedding = self.word_embeddings(sentence)    \n",
    "        hidden_state, _ = self.gru(word_embedding)\n",
    "        aspect_embedding = self.aspect_embeddings(aspect)\n",
    "\n",
    "        # Resize aspect embedding for sentence length in batch\n",
    "        aspect_embedding = aspect_embedding.unsqueeze_(1)\n",
    "        aspect_embedding = aspect_embedding.expand(-1, sentence[0].size()[0], -1) \n",
    "\n",
    "        # Concat hidden_state and aspect_embedding for attention calculation\n",
    "        hidden_plus_aspect = torch.cat((hidden_state, aspect_embedding), dim=2)\n",
    "\n",
    "        # Positive attention calculation\n",
    "        positive_attention = torch.tanh(F.linear(hidden_plus_aspect, self.W_p) + self.b_p)\n",
    "        positive_attention = F.linear(positive_attention, self.u_p)\n",
    "        # Remove 3-dim and transpose to get (sentence_length, batch_size)\n",
    "        positive_attention = positive_attention.squeeze().t()\n",
    "        # Attention calculation for each word in sentence \n",
    "        positive_attention = self.softmax(positive_attention)\n",
    "\n",
    "        # Negative attention calculation\n",
    "        negative_attention = torch.tanh(F.linear(hidden_plus_aspect, self.W_n) + self.b_n)\n",
    "        negative_attention = F.linear(negative_attention, self.u_n)\n",
    "        # Remove 3-dim and transpose to get (sentence_length, batch_size)\n",
    "        negative_attention = negative_attention.squeeze().t()\n",
    "        # Attention calculation for each word in sentence, in word order position\n",
    "        negative_attention = self.softmax(negative_attention)\n",
    "\n",
    "        print(positive_attention)\n",
    "        print(positive_attention.shape)\n",
    "        print(negative_attention)\n",
    "        print(negative_attention.shape)\n",
    "\n",
    "        return null\n",
    "    \n",
    "    def init_random(self, x_size, ysize):\n",
    "        empty = torch.empty(x_size, ysize, dtype=torch.float32, requires_grad=True)\n",
    "        return nn.init.normal_(empty, mean=0, std=0.01)"
   ]
  },
  {
   "source": [
    "## Training cycle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, lr, num_epochs):\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    losses_average = []    \n",
    "    for epoch in range(1,num_epochs+1):       \n",
    "        # Remise Ã  zÃ©ro des gradients\n",
    "        optimizer.zero_grad()\n",
    "        batch_idx = 0\n",
    "        epoch_losses = []\n",
    "        for data, aspect, target in dataset:\n",
    "            batch_idx += 1\n",
    "            # Get Samples\n",
    "            data, aspect, target = Variable(data), Variable(aspect), Variable(target)\n",
    "            \n",
    "            # PrÃ©diction\n",
    "            pred = model(data, aspect)\n",
    "            print(pred)\n",
    "\n",
    "            # Calculer la cross_entropy loss\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(pred, target)\n",
    "\n",
    "            # Sauvegarde des losses pour affichage\n",
    "            epoch_losses.append(loss.data.item())\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "                      \n",
    "            # Affichage\n",
    "            print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(epoch,batch_idx * len(data),len(dataset)*len(data),100. * batch_idx / len(dataset), np.average(epoch_losses)), end='')\n",
    "        print()\n",
    "        losses_average.append(np.average(epoch_losses))\n",
    "    print(\"Evolution of average losse for each epoch:\")\n",
    "    plot(losses_average)\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n         0.1000],\n        [0.0999, 0.0999, 0.0998, 0.1000, 0.1002, 0.1001, 0.0999, 0.1001, 0.1001,\n         0.1000],\n        [0.0998, 0.0996, 0.0999, 0.1001, 0.1001, 0.1002, 0.0999, 0.1000, 0.1000,\n         0.1002],\n        [0.0998, 0.1002, 0.0999, 0.1000, 0.1000, 0.1001, 0.1001, 0.1001, 0.0999,\n         0.1002],\n        [0.1002, 0.0999, 0.0999, 0.0998, 0.0997, 0.1002, 0.0999, 0.1004, 0.1001,\n         0.1000],\n        [0.0999, 0.1001, 0.0998, 0.0996, 0.0997, 0.1003, 0.1001, 0.1003, 0.1004,\n         0.0998],\n        [0.0997, 0.1003, 0.0996, 0.0998, 0.0996, 0.1004, 0.1002, 0.0998, 0.1006,\n         0.1001],\n        [0.0998, 0.1004, 0.0999, 0.0997, 0.0996, 0.1005, 0.0999, 0.0998, 0.1000,\n         0.1003],\n        [0.0999, 0.1003, 0.1002, 0.0999, 0.0996, 0.1003, 0.0998, 0.0999, 0.1000,\n         0.1002],\n        [0.0997, 0.1003, 0.1001, 0.1000, 0.0998, 0.1003, 0.0997, 0.1001, 0.0998,\n         0.1002],\n        [0.1003, 0.1003, 0.0995, 0.1001, 0.1002, 0.1002, 0.0996, 0.0997, 0.0999,\n         0.1002],\n        [0.0999, 0.1003, 0.0996, 0.1002, 0.1002, 0.1003, 0.0993, 0.0999, 0.1000,\n         0.1002],\n        [0.0998, 0.1003, 0.0996, 0.1002, 0.1002, 0.1002, 0.0994, 0.1000, 0.1001,\n         0.1002],\n        [0.0998, 0.1002, 0.0997, 0.1001, 0.1001, 0.1001, 0.0996, 0.1000, 0.1001,\n         0.1001],\n        [0.0996, 0.1002, 0.0999, 0.1001, 0.1001, 0.1001, 0.0998, 0.1001, 0.1001,\n         0.1001],\n        [0.0996, 0.1001, 0.0999, 0.1001, 0.1001, 0.1001, 0.0999, 0.1001, 0.1001,\n         0.1001],\n        [0.0998, 0.1001, 0.0999, 0.1001, 0.1000, 0.1000, 0.0999, 0.1000, 0.1000,\n         0.1000],\n        [0.0999, 0.1001, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n         0.1000],\n        [0.0999, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n         0.1000],\n        [0.0995, 0.1001, 0.1000, 0.1001, 0.1000, 0.1001, 0.1001, 0.1001, 0.1000,\n         0.1001],\n        [0.0997, 0.1001, 0.1000, 0.1001, 0.1000, 0.1000, 0.1000, 0.1001, 0.1000,\n         0.1000],\n        [0.0995, 0.1001, 0.1000, 0.1001, 0.1000, 0.1000, 0.1001, 0.1001, 0.1000,\n         0.1000]], grad_fn=<SoftmaxBackward>)\ntorch.Size([22, 10])\ntensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n         0.1000],\n        [0.0999, 0.0999, 0.0998, 0.1000, 0.1002, 0.1001, 0.0999, 0.1001, 0.1001,\n         0.1000],\n        [0.0998, 0.0996, 0.0999, 0.1001, 0.1001, 0.1002, 0.0999, 0.1000, 0.1000,\n         0.1002],\n        [0.0998, 0.1002, 0.0999, 0.1000, 0.1000, 0.1001, 0.1001, 0.1001, 0.0999,\n         0.1002],\n        [0.1002, 0.0999, 0.0999, 0.0998, 0.0997, 0.1002, 0.0999, 0.1004, 0.1001,\n         0.1000],\n        [0.0999, 0.1001, 0.0998, 0.0996, 0.0997, 0.1003, 0.1001, 0.1003, 0.1004,\n         0.0998],\n        [0.0997, 0.1003, 0.0996, 0.0998, 0.0996, 0.1004, 0.1002, 0.0998, 0.1006,\n         0.1001],\n        [0.0998, 0.1004, 0.0999, 0.0997, 0.0996, 0.1005, 0.0999, 0.0998, 0.1000,\n         0.1003],\n        [0.0999, 0.1003, 0.1002, 0.0999, 0.0996, 0.1003, 0.0998, 0.0999, 0.1000,\n         0.1002],\n        [0.0997, 0.1003, 0.1001, 0.1000, 0.0998, 0.1003, 0.0997, 0.1001, 0.0998,\n         0.1002],\n        [0.1003, 0.1003, 0.0995, 0.1001, 0.1002, 0.1002, 0.0996, 0.0997, 0.0999,\n         0.1002],\n        [0.0999, 0.1003, 0.0996, 0.1002, 0.1002, 0.1003, 0.0993, 0.0999, 0.1000,\n         0.1002],\n        [0.0998, 0.1003, 0.0996, 0.1002, 0.1002, 0.1002, 0.0994, 0.1000, 0.1001,\n         0.1002],\n        [0.0998, 0.1002, 0.0997, 0.1001, 0.1001, 0.1001, 0.0996, 0.1000, 0.1001,\n         0.1001],\n        [0.0996, 0.1002, 0.0999, 0.1001, 0.1001, 0.1001, 0.0998, 0.1001, 0.1001,\n         0.1001],\n        [0.0996, 0.1001, 0.0999, 0.1001, 0.1001, 0.1001, 0.0999, 0.1001, 0.1001,\n         0.1001],\n        [0.0998, 0.1001, 0.0999, 0.1001, 0.1000, 0.1000, 0.0999, 0.1000, 0.1000,\n         0.1000],\n        [0.0999, 0.1001, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n         0.1000],\n        [0.0999, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n         0.1000],\n        [0.0995, 0.1001, 0.1000, 0.1001, 0.1000, 0.1001, 0.1001, 0.1001, 0.1000,\n         0.1001],\n        [0.0997, 0.1001, 0.1000, 0.1001, 0.1000, 0.1000, 0.1000, 0.1001, 0.1000,\n         0.1000],\n        [0.0995, 0.1001, 0.1000, 0.1001, 0.1000, 0.1000, 0.1001, 0.1001, 0.1000,\n         0.1000]], grad_fn=<SoftmaxBackward>)\ntorch.Size([22, 10])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-5cdfa1664916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_AT_GRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tensordataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-155-2a4ba59fcbdd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, lr, num_epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# PrÃ©diction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-18dc5d200879>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence, aspect)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "train(D_AT_GRU(pretrained_embeds, len(aspects)), to_tensordataset(corpus, vocab, aspects, 10), 0.01, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}